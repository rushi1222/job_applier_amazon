name: Multi-Company Job Scraper

on:
  schedule:
    # Run every 30 minutes (GitHub Actions free tier may have delays)
    - cron: '*/30 * * * *'  # Every 30 minutes, all day
  workflow_dispatch:  # Allow manual runs

jobs:
  scrape-jobs:
    runs-on: ubuntu-latest
    permissions:
      contents: write  # Allow pushing datastore updates back to repo
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
        
    - name: Install Chrome
      run: |
        # Install Chrome using the official method
        wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
        sudo sh -c 'echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google-chrome.list'
        sudo apt-get update
        sudo apt-get install -y google-chrome-stable
        
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        
    - name: Verify Chrome installation
      run: |
        google-chrome --version
        which google-chrome
        
    - name: Run job scraper
      timeout-minutes: 10
      env:
        GMAIL_SENDER_EMAIL: ${{ secrets.GMAIL_SENDER_EMAIL }}
        GMAIL_SENDER_PASSWORD: ${{ secrets.GMAIL_SENDER_PASSWORD }}
        RECIPIENT_EMAIL: ${{ secrets.RECIPIENT_EMAIL }}
        CI: true
      run: |
        # Retry logic for transient failures
        MAX_RETRIES=2
        RETRY_COUNT=0
        
        while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
          echo "Attempt $((RETRY_COUNT + 1)) of $MAX_RETRIES"
          
          if python main.py; then
            echo "✅ Job scraper completed successfully"
            exit 0
          else
            RETRY_COUNT=$((RETRY_COUNT + 1))
            if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
              echo "⚠️ Attempt failed, retrying in 30 seconds..."
              # Kill any hanging Chrome processes
              pkill -9 chrome || true
              pkill -9 chromedriver || true
              sleep 30
            fi
          fi
        done
        
        echo "❌ All retry attempts failed"
        exit 1
    
    - name: Cleanup Chrome processes
      if: always()
      run: |
        pkill -9 chrome || true
        pkill -9 chromedriver || true
        
    - name: Commit datastore updates
      if: success() || failure()  # Run even if scraper fails to save partial results
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add data/*/
        if git diff --staged --quiet; then
          echo "No new jobs found, nothing to commit"
        else
          git commit -m "Update job datastores - $(date '+%Y-%m-%d %H:%M:%S')"
          git push || echo "Failed to push changes"
        fi