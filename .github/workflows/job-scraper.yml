name: Multi-Company Job Scraper

on:
  schedule:
    # Run every 30 minutes (GitHub Actions free tier may have delays)
    - cron: '*/30 * * * *'  # Every 30 minutes, all day
  workflow_dispatch:  # Allow manual runs

jobs:
  scrape-jobs:
    runs-on: ubuntu-latest
    permissions:
      contents: write  # Allow pushing datastore updates back to repo
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
        
    - name: Install Chrome
      uses: browser-actions/setup-chrome@v1
      with:
        chrome-version: stable
        
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        
    - name: Run job scraper
      env:
        GMAIL_SENDER_EMAIL: ${{ secrets.GMAIL_SENDER_EMAIL }}
        GMAIL_SENDER_PASSWORD: ${{ secrets.GMAIL_SENDER_PASSWORD }}
        RECIPIENT_EMAIL: ${{ secrets.RECIPIENT_EMAIL }}
      run: |
        python main.py
        
    - name: Commit datastore updates
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add data/*/
        if git diff --staged --quiet; then
          echo "No new jobs found, nothing to commit"
        else
          git commit -m "Update job datastores - $(date '+%Y-%m-%d %H:%M:%S')"
          git push
        fi