name: Multi-Company Job Scraper

on:
  schedule:
    # Run every 30 minutes (GitHub Actions free tier may have delays)
    - cron: '*/30 * * * *'  # Every 30 minutes, all day
  workflow_dispatch:  # Allow manual runs

jobs:
  scrape-jobs:
    runs-on: ubuntu-latest
    permissions:
      contents: write  # Allow pushing datastore updates back to repo
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
        
    - name: Install Chrome
      run: |
        # Install Chrome using the official method
        wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
        sudo sh -c 'echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google-chrome.list'
        sudo apt-get update
        sudo apt-get install -y google-chrome-stable
        
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        
    - name: Verify Chrome installation
      run: |
        google-chrome --version
        which google-chrome
        
    - name: Run job scraper
      env:
        GMAIL_SENDER_EMAIL: ${{ secrets.GMAIL_SENDER_EMAIL }}
        GMAIL_SENDER_PASSWORD: ${{ secrets.GMAIL_SENDER_PASSWORD }}
        RECIPIENT_EMAIL: ${{ secrets.RECIPIENT_EMAIL }}
        CI: true
      run: |
        python main.py
        
    - name: Commit datastore updates
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add data/*/
        if git diff --staged --quiet; then
          echo "No new jobs found, nothing to commit"
        else
          git commit -m "Update job datastores - $(date '+%Y-%m-%d %H:%M:%S')"
          git push
        fi